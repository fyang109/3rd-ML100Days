{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Day_100_transfer_learning_HW.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2OpLU5q5dOrJ","colab_type":"text"},"source":["## 作業\n","礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n","\n","\n","最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n","\n","另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"]},{"cell_type":"code","metadata":{"id":"TOcizc0zdOrN","colab_type":"code","outputId":"34487fe5-9cd4-497a-8960-a06e6e7fe744","executionInfo":{"status":"ok","timestamp":1579584414682,"user_tz":-480,"elapsed":1751,"user":{"displayName":"楊豐豪","photoUrl":"","userId":"02756875908311025376"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["from keras.datasets import cifar10\n","# from resnet_builder import resnet # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.applications.resnet50 import ResNet50\n","from keras import backend as K\n","from keras.layers import Flatten, Dense, Dropout\n","from keras.applications.resnet50 import ResNet50\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","import numpy as np"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"dA-vjjJQdOrS","colab_type":"code","outputId":"ec34b566-b327-4df4-dc9e-a262ce61342e","executionInfo":{"status":"ok","timestamp":1579584415134,"user_tz":-480,"elapsed":2192,"user":{"displayName":"楊豐豪","photoUrl":"","userId":"02756875908311025376"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["# 讀取資料集並作前處理\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train = x_train / 255.\n","x_test = x_test / 255.\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"37OALF4sdOra","colab_type":"code","outputId":"be48f6df-d03d-493d-d405-a55e8d647cb7","executionInfo":{"status":"ok","timestamp":1579584422851,"user_tz":-480,"elapsed":9876,"user":{"displayName":"楊豐豪","photoUrl":"","userId":"02756875908311025376"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["batch_size = 50 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 100 # 訓練整個資料集共 100個循環\n","\n","# 以訓練好的 ResNet50 為基礎來建立模型，\n","# 捨棄 ResNet50 頂層的 fully connected layers\n","net = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(32,32,3))\n","x = net.output\n","x = Flatten()(x)\n","\n","# 增加 DropOut layer\n","x = Dropout(0.5)(x)\n","\n","# 增加 Dense layer，以 softmax 產生個類別的機率值\n","output_layer = Dense(num_classes, activation='softmax', name='softmax')(x)\n","\n","# 設定凍結與要進行訓練的網路層\n","FREEZE_LAYERS = 2\n","net_final = Model(inputs=net.input, outputs=output_layer)\n","for layer in net_final.layers[:FREEZE_LAYERS]:\n","    layer.trainable = False\n","for layer in net_final.layers[FREEZE_LAYERS:]:\n","    layer.trainable = True\n","\n","# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n","net_final.compile(optimizer=Adam(lr=1e-5),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","# 輸出整個網路結構\n","print(net_final.summary())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 16, 16, 64)   256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 16, 16, 64)   0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 8, 8, 64)     4160        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 8, 8, 256)    16640       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 8, 8, 256)    1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 8, 8, 256)    0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 8, 8, 256)    0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 8, 8, 256)    0           bn2b_branch2c[0][0]              \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 8, 8, 256)    0           bn2c_branch2c[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 8, 8, 256)    0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 4, 4, 512)    0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n","                                                                 activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 4, 4, 512)    0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n","                                                                 activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 2, 2, 1024)   0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 1, 1, 2048)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 2048)         0           activation_49[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 2048)         0           flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","softmax (Dense)                 (None, 10)           20490       dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 23,608,202\n","Trainable params: 23,555,082\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9LEhfnS0dOre","colab_type":"code","outputId":"3516419c-cd0a-44fe-9c1e-9ce54568d525","executionInfo":{"status":"ok","timestamp":1579609372019,"user_tz":-480,"elapsed":8896076,"user":{"displayName":"楊豐豪","photoUrl":"","userId":"02756875908311025376"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# 透過 data augmentation 產生訓練與驗證用的影像資料\n","train_datagen = ImageDataGenerator(rotation_range=10,\n","                                   width_shift_range=0.1,\n","                                   height_shift_range=0.1,\n","                                   horizontal_flip=True)\n","\n","net_final.fit_generator(train_datagen.flow(x_train, y_train, shuffle=True, batch_size=batch_size),\n","                        steps_per_epoch=np.trunc(x_train.shape[0]/batch_size),\n","                        epochs=epochs,\n","                        verbose=1,\n","                        validation_data=(x_test, y_test),\n","                        validation_steps=np.trunc(x_test.shape[0]/batch_size))\n","\n","score = net_final.evaluate(x_test, y_test, verbose=0)\n","\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0512 - acc: 0.9831 - val_loss: 0.6717 - val_acc: 0.8553\n","Epoch 2/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0454 - acc: 0.9851 - val_loss: 0.6938 - val_acc: 0.8541\n","Epoch 3/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0463 - acc: 0.9853 - val_loss: 0.6855 - val_acc: 0.8560\n","Epoch 4/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0480 - acc: 0.9845 - val_loss: 0.6879 - val_acc: 0.8521\n","Epoch 5/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0445 - acc: 0.9852 - val_loss: 0.6938 - val_acc: 0.8510\n","Epoch 6/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0472 - acc: 0.9844 - val_loss: 0.6791 - val_acc: 0.8565\n","Epoch 7/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0434 - acc: 0.9852 - val_loss: 0.7321 - val_acc: 0.8517\n","Epoch 8/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0491 - acc: 0.9838 - val_loss: 0.6775 - val_acc: 0.8526\n","Epoch 9/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0440 - acc: 0.9856 - val_loss: 0.6945 - val_acc: 0.8511\n","Epoch 10/100\n","1000/1000 [==============================] - 94s 94ms/step - loss: 0.0457 - acc: 0.9851 - val_loss: 0.7043 - val_acc: 0.8528\n","Epoch 11/100\n","1000/1000 [==============================] - 91s 91ms/step - loss: 0.0444 - acc: 0.9849 - val_loss: 0.6724 - val_acc: 0.8550\n","Epoch 12/100\n","1000/1000 [==============================] - 91s 91ms/step - loss: 0.0438 - acc: 0.9855 - val_loss: 0.6874 - val_acc: 0.8538\n","Epoch 13/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0455 - acc: 0.9848 - val_loss: 0.6974 - val_acc: 0.8501\n","Epoch 14/100\n","1000/1000 [==============================] - 91s 91ms/step - loss: 0.0457 - acc: 0.9847 - val_loss: 0.6873 - val_acc: 0.8555\n","Epoch 15/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0429 - acc: 0.9852 - val_loss: 0.6921 - val_acc: 0.8555\n","Epoch 16/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0428 - acc: 0.9853 - val_loss: 0.6620 - val_acc: 0.8556\n","Epoch 17/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0441 - acc: 0.9857 - val_loss: 0.6990 - val_acc: 0.8531\n","Epoch 18/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0428 - acc: 0.9864 - val_loss: 0.6632 - val_acc: 0.8575\n","Epoch 19/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0403 - acc: 0.9869 - val_loss: 0.6842 - val_acc: 0.8522\n","Epoch 20/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0433 - acc: 0.9856 - val_loss: 0.6686 - val_acc: 0.8560\n","Epoch 21/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0391 - acc: 0.9869 - val_loss: 0.7102 - val_acc: 0.8486\n","Epoch 22/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0402 - acc: 0.9868 - val_loss: 0.6889 - val_acc: 0.8522\n","Epoch 23/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0405 - acc: 0.9864 - val_loss: 0.7222 - val_acc: 0.8516\n","Epoch 24/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0409 - acc: 0.9868 - val_loss: 0.6673 - val_acc: 0.8555\n","Epoch 25/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0414 - acc: 0.9868 - val_loss: 0.6902 - val_acc: 0.8539\n","Epoch 26/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0424 - acc: 0.9857 - val_loss: 0.6968 - val_acc: 0.8537\n","Epoch 27/100\n","1000/1000 [==============================] - 91s 91ms/step - loss: 0.0392 - acc: 0.9873 - val_loss: 0.6744 - val_acc: 0.8540\n","Epoch 28/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0375 - acc: 0.9879 - val_loss: 0.7142 - val_acc: 0.8516\n","Epoch 29/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0427 - acc: 0.9863 - val_loss: 0.6731 - val_acc: 0.8579\n","Epoch 30/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0373 - acc: 0.9880 - val_loss: 0.7067 - val_acc: 0.8546\n","Epoch 31/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0396 - acc: 0.9872 - val_loss: 0.6666 - val_acc: 0.8586\n","Epoch 32/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0380 - acc: 0.9875 - val_loss: 0.6762 - val_acc: 0.8560\n","Epoch 33/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0369 - acc: 0.9877 - val_loss: 0.7038 - val_acc: 0.8539\n","Epoch 34/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0392 - acc: 0.9870 - val_loss: 0.6877 - val_acc: 0.8535\n","Epoch 35/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0373 - acc: 0.9880 - val_loss: 0.6997 - val_acc: 0.8516\n","Epoch 36/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0364 - acc: 0.9879 - val_loss: 0.7325 - val_acc: 0.8494\n","Epoch 37/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0337 - acc: 0.9889 - val_loss: 0.7235 - val_acc: 0.8517\n","Epoch 38/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0352 - acc: 0.9884 - val_loss: 0.6966 - val_acc: 0.8544\n","Epoch 39/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0383 - acc: 0.9875 - val_loss: 0.6882 - val_acc: 0.8538\n","Epoch 40/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0365 - acc: 0.9885 - val_loss: 0.6644 - val_acc: 0.8580\n","Epoch 41/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0361 - acc: 0.9881 - val_loss: 0.6869 - val_acc: 0.8555\n","Epoch 42/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0359 - acc: 0.9880 - val_loss: 0.7316 - val_acc: 0.8526\n","Epoch 43/100\n","1000/1000 [==============================] - 90s 90ms/step - loss: 0.0377 - acc: 0.9876 - val_loss: 0.7114 - val_acc: 0.8554\n","Epoch 44/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0348 - acc: 0.9887 - val_loss: 0.6979 - val_acc: 0.8597\n","Epoch 45/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0340 - acc: 0.9889 - val_loss: 0.7196 - val_acc: 0.8578\n","Epoch 46/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0340 - acc: 0.9884 - val_loss: 0.6885 - val_acc: 0.8600\n","Epoch 47/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0364 - acc: 0.9880 - val_loss: 0.6749 - val_acc: 0.8580\n","Epoch 48/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0342 - acc: 0.9888 - val_loss: 0.7300 - val_acc: 0.8529\n","Epoch 49/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0338 - acc: 0.9888 - val_loss: 0.7107 - val_acc: 0.8548\n","Epoch 50/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0327 - acc: 0.9891 - val_loss: 0.6884 - val_acc: 0.8566\n","Epoch 51/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0329 - acc: 0.9891 - val_loss: 0.7430 - val_acc: 0.8524\n","Epoch 52/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0347 - acc: 0.9888 - val_loss: 0.6964 - val_acc: 0.8563\n","Epoch 53/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0330 - acc: 0.9891 - val_loss: 0.7176 - val_acc: 0.8576\n","Epoch 54/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0334 - acc: 0.9887 - val_loss: 0.7186 - val_acc: 0.8551\n","Epoch 55/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0310 - acc: 0.9904 - val_loss: 0.7286 - val_acc: 0.8555\n","Epoch 56/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0345 - acc: 0.9887 - val_loss: 0.6951 - val_acc: 0.8553\n","Epoch 57/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0326 - acc: 0.9895 - val_loss: 0.7057 - val_acc: 0.8588\n","Epoch 58/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0317 - acc: 0.9892 - val_loss: 0.7272 - val_acc: 0.8564\n","Epoch 59/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0326 - acc: 0.9893 - val_loss: 0.7092 - val_acc: 0.8587\n","Epoch 60/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0305 - acc: 0.9895 - val_loss: 0.7300 - val_acc: 0.8590\n","Epoch 61/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0296 - acc: 0.9900 - val_loss: 0.7211 - val_acc: 0.8529\n","Epoch 62/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0300 - acc: 0.9910 - val_loss: 0.7124 - val_acc: 0.8589\n","Epoch 63/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0322 - acc: 0.9891 - val_loss: 0.6945 - val_acc: 0.8559\n","Epoch 64/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0316 - acc: 0.9901 - val_loss: 0.6999 - val_acc: 0.8577\n","Epoch 65/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0294 - acc: 0.9909 - val_loss: 0.7160 - val_acc: 0.8545\n","Epoch 66/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0324 - acc: 0.9893 - val_loss: 0.7253 - val_acc: 0.8536\n","Epoch 67/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0302 - acc: 0.9903 - val_loss: 0.7210 - val_acc: 0.8557\n","Epoch 68/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0307 - acc: 0.9896 - val_loss: 0.6948 - val_acc: 0.8563\n","Epoch 69/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0293 - acc: 0.9903 - val_loss: 0.7264 - val_acc: 0.8552\n","Epoch 70/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0274 - acc: 0.9914 - val_loss: 0.7154 - val_acc: 0.8553\n","Epoch 71/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0305 - acc: 0.9897 - val_loss: 0.7411 - val_acc: 0.8528\n","Epoch 72/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0306 - acc: 0.9898 - val_loss: 0.6996 - val_acc: 0.8536\n","Epoch 73/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0280 - acc: 0.9906 - val_loss: 0.7691 - val_acc: 0.8501\n","Epoch 74/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0295 - acc: 0.9896 - val_loss: 0.7063 - val_acc: 0.8558\n","Epoch 75/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0303 - acc: 0.9902 - val_loss: 0.7186 - val_acc: 0.8534\n","Epoch 76/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0307 - acc: 0.9904 - val_loss: 0.7263 - val_acc: 0.8551\n","Epoch 77/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0287 - acc: 0.9907 - val_loss: 0.7217 - val_acc: 0.8547\n","Epoch 78/100\n","1000/1000 [==============================] - 89s 89ms/step - loss: 0.0299 - acc: 0.9898 - val_loss: 0.7316 - val_acc: 0.8554\n","Epoch 79/100\n","1000/1000 [==============================] - 87s 87ms/step - loss: 0.0273 - acc: 0.9911 - val_loss: 0.7473 - val_acc: 0.8547\n","Epoch 80/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0291 - acc: 0.9907 - val_loss: 0.7442 - val_acc: 0.8525\n","Epoch 81/100\n","1000/1000 [==============================] - 87s 87ms/step - loss: 0.0277 - acc: 0.9910 - val_loss: 0.7346 - val_acc: 0.8596\n","Epoch 82/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0292 - acc: 0.9909 - val_loss: 0.7263 - val_acc: 0.8573\n","Epoch 83/100\n","1000/1000 [==============================] - 87s 87ms/step - loss: 0.0271 - acc: 0.9908 - val_loss: 0.7356 - val_acc: 0.8534\n","Epoch 84/100\n","1000/1000 [==============================] - 87s 87ms/step - loss: 0.0257 - acc: 0.9914 - val_loss: 0.7232 - val_acc: 0.8561\n","Epoch 85/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0281 - acc: 0.9908 - val_loss: 0.7397 - val_acc: 0.8550\n","Epoch 86/100\n","1000/1000 [==============================] - 87s 87ms/step - loss: 0.0298 - acc: 0.9903 - val_loss: 0.7054 - val_acc: 0.8565\n","Epoch 87/100\n","1000/1000 [==============================] - 87s 87ms/step - loss: 0.0256 - acc: 0.9916 - val_loss: 0.7827 - val_acc: 0.8464\n","Epoch 88/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0271 - acc: 0.9909 - val_loss: 0.7154 - val_acc: 0.8583\n","Epoch 89/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0288 - acc: 0.9910 - val_loss: 0.7445 - val_acc: 0.8524\n","Epoch 90/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0276 - acc: 0.9910 - val_loss: 0.7434 - val_acc: 0.8545\n","Epoch 91/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0263 - acc: 0.9914 - val_loss: 0.7156 - val_acc: 0.8548\n","Epoch 92/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0277 - acc: 0.9915 - val_loss: 0.7019 - val_acc: 0.8554\n","Epoch 93/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0275 - acc: 0.9907 - val_loss: 0.6953 - val_acc: 0.8570\n","Epoch 94/100\n","1000/1000 [==============================] - 87s 87ms/step - loss: 0.0266 - acc: 0.9910 - val_loss: 0.7271 - val_acc: 0.8557\n","Epoch 95/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0283 - acc: 0.9909 - val_loss: 0.7083 - val_acc: 0.8556\n","Epoch 96/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0291 - acc: 0.9908 - val_loss: 0.7025 - val_acc: 0.8550\n","Epoch 97/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0265 - acc: 0.9915 - val_loss: 0.7139 - val_acc: 0.8552\n","Epoch 98/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0257 - acc: 0.9915 - val_loss: 0.7199 - val_acc: 0.8584\n","Epoch 99/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0285 - acc: 0.9907 - val_loss: 0.7014 - val_acc: 0.8567\n","Epoch 100/100\n","1000/1000 [==============================] - 88s 88ms/step - loss: 0.0251 - acc: 0.9918 - val_loss: 0.7232 - val_acc: 0.8584\n","Test loss: 0.7232463210463523\n","Test accuracy: 0.8584\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jOqNwyZb9_rx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}